{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b417323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "828c5eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class GridWorld:\n",
    "    def __init__(self):\n",
    "        self.height = 5\n",
    "        self.width = 5\n",
    "        self.actions = ['north', 'south', 'east', 'west']\n",
    "        \n",
    "        self.special_states = {\n",
    "            (0, 1): {'next_state': (4, 1), 'reward': 10},  # A to A′\n",
    "            (0, 3): {'next_state': (2, 3), 'reward': 5}    # B to B′\n",
    "        }\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_state = (random.randint(0, 4), random.randint(0, 4))\n",
    "        return self.current_state\n",
    "\n",
    "    def get_available_actions(self):\n",
    "        return self.actions\n",
    "\n",
    "    def step(self, action):\n",
    "        state = self.current_state\n",
    "\n",
    "        # Check if current state is special (A or B)\n",
    "        if state in self.special_states:\n",
    "            special = self.special_states[state]\n",
    "            self.current_state = special['next_state']\n",
    "            return self.current_state, special['reward']\n",
    "        \n",
    "        # Default reward for valid move\n",
    "        reward = 0\n",
    "        x, y = state\n",
    "\n",
    "        if action == 'north':\n",
    "            new_state = (x - 1, y) if x > 0 else state\n",
    "        elif action == 'south':\n",
    "            new_state = (x + 1, y) if x < self.height - 1 else state\n",
    "        elif action == 'east':\n",
    "            new_state = (x, y + 1) if y < self.width - 1 else state\n",
    "        elif action == 'west':\n",
    "            new_state = (x, y - 1) if y > 0 else state\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action\")\n",
    "\n",
    "        # If the agent hits the wall (no movement), give -1\n",
    "        if new_state == state:\n",
    "            reward = -1\n",
    "\n",
    "        self.current_state = new_state\n",
    "        return new_state, reward\n",
    "\n",
    "    def render(self):\n",
    "        grid = np.full((self.height, self.width), '.')\n",
    "        grid[self.current_state] = 'A'\n",
    "        print(grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c4b1231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, List\n",
    "\n",
    "class QTable:\n",
    "    def __init__(self, states: List[Tuple[int, int]], actions: List[str]):\n",
    "        self.q_table = {}\n",
    "        for state in states:\n",
    "            self.q_table[state] = {action: 0.0 for action in actions}\n",
    "    \n",
    "    def get_q_value(self, state: Tuple[int, int], action: str) -> float:\n",
    "        return self.q_table[state][action]\n",
    "    \n",
    "    def get_max_q_value(self, state: Tuple[int, int]) -> float:\n",
    "        return max(self.q_table[state].values())\n",
    "    \n",
    "    def get_best_action(self, state: Tuple[int, int]) -> str:\n",
    "        max_q = self.get_max_q_value(state)\n",
    "        best_actions = [a for a, q in self.q_table[state].items() if q == max_q]\n",
    "        return random.choice(best_actions)\n",
    "    \n",
    "    def update(self, state: Tuple[int, int], action: str, reward: float, \n",
    "               next_state: Tuple[int, int], alpha: float, gamma: float):\n",
    "        current_q = self.get_q_value(state, action)\n",
    "        max_next_q = self.get_max_q_value(next_state)\n",
    "        new_q = current_q + alpha * (reward + gamma * max_next_q - current_q)\n",
    "        self.q_table[state][action] = new_q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
